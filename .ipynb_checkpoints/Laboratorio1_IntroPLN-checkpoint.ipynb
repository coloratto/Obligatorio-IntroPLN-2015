{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hay que instalar python 3\n",
    "# Para esto... http://continuum.io/blog/anaconda-python-3\n",
    "import nltk\n",
    "import pandas\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importamos el corpus de comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datos = pandas.read_csv(\"comentarios_peliculas.csv\", skiprows=1, delimiter=';', skip_blank_lines=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Descartamos columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#se extraen de los datos solamente los comentarios y sus calificaiones\n",
    "comentarios = datos.ComTexto\n",
    "estrellas = datos.ix[:,7] #se extrajo de esta forma ya que datos.Calificación no funciona por el tilde\n",
    "\n",
    "comentarios_estrellas = []\n",
    "for i in range(0,len(datos)):\n",
    "    comentarios_estrellas.insert(i,(comentarios[i],estrellas[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocesamiento de los comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#se quitan los espacios en blanco (espacio, tab, retorno de carro, salto de linea)\n",
    "\n",
    "for i in range(0,len(comentarios_estrellas)):\n",
    "    comentarios_estrellas[i] = (comentarios_estrellas[i][0].strip(' \\t\\n\\r'),comentarios_estrellas[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#se quitan las etiquetas html\n",
    "\n",
    "for i in range(0,len(comentarios_estrellas)):\n",
    "    length = len(comentarios_estrellas[i][0])\n",
    "    new_length = 0\n",
    "    reg = r'<\\/?\\w+((\\s+\\w+(\\s*=\\s*(?:\".*?\"|\\'.*?\\'|[^\\'\">\\s]+))?)+\\s*|\\s*)\\/?>'\n",
    "    while new_length != length:\n",
    "        new_comment = re.sub(reg, \"\", comentarios_estrellas[i][0])\n",
    "        comentarios_estrellas[i] = (new_comment,comentarios_estrellas[i][1])\n",
    "        new_length = len(comentarios_estrellas[i][0])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Características del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cantidad de peliculas\n",
    "print \"El corpus posee una cantidad de \" + str(len(datos.ix[:,0].unique())) + \" películas.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cantidad de comentarios\n",
    "print \"El corpus posee una cantidad de \" + str(len(comentarios_estrellas)) + \" comentarios.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cantidad de comentarios para cada pelicula\n",
    "print \"Cantidad de comentarios asociados a cada película:\\n\"\n",
    "print datos.ix[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Retorna un diccionario (dict) palabra-frecuencia de las palabras del corpus\n",
    "dic = {}\n",
    "\n",
    "#se recorren los comentarios y para cada uno de ellos se tokeniza con nltk\n",
    "for comentario in comentarios_estrellas:\n",
    "    for palabra in nltk.word_tokenize(comentario[0]):\n",
    "        if(palabra.lower() in dic): #se consideran las palabras en minúscula: \"El\" = \"el\", y se guarda como \"el\"\n",
    "            dic[palabra.lower()] = dic[palabra.lower()] + 1\n",
    "        else:\n",
    "            dic[palabra.lower()] = 1 \n",
    "print dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Separamos entrenamiento y testeo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "np.random.seed(42)\n",
    "msk = np.random.rand(len(comentarios)) < 0.8\n",
    "comentarios_training= comentarios[msk]\n",
    "comentarios_testing = comentarios[~msk]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
